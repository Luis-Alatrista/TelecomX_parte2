{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luis-Alatrista/TelecomX_parte2/blob/main/Copia_de_TelecomX_parte2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb873f90",
      "metadata": {
        "id": "bb873f90"
      },
      "source": [
        "# Telecom X — Modelado Predictivo de Churn (Parte 2)\n",
        "\n",
        "**Objetivo:** Construir un pipeline robusto para predecir cancelación de clientes (*churn*), usando el dataset **limpio** de la Parte 1 (`telecomx_churn_clean.csv`).\n",
        "\n",
        "**Contenido:**\n",
        "1. Preparación de datos (carga, selección de columnas relevantes, codificación, escalado opcional).\n",
        "2. Análisis de desbalance de clases y opciones de balanceo (SMOTE / undersampling).\n",
        "3. Visualizaciones: correlaciones, boxplots/scatter de variables clave vs churn.\n",
        "4. Modelado con **2 enfoques**:\n",
        "   - **Regresión Logística** (requiere normalización).\n",
        "   - **Random Forest** (no requiere normalización).\n",
        "5. Evaluación (accuracy, precision, recall, F1, matriz de confusión) y comparación crítica.\n",
        "6. Interpretabilidad (coeficientes / importancias) e **informe final** con insights y recomendaciones.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad4b4ad",
      "metadata": {
        "id": "3ad4b4ad"
      },
      "source": [
        "## 1) Carga y preparación de datos\n",
        "\n",
        "- Se utiliza el archivo limpio `telecomx_churn_clean.csv` (generado en la Parte 1).\n",
        "- Se eliminan columnas que **no aportan valor predictivo** (IDs u otros identificadores únicos).\n",
        "- Se detecta de forma **robusta** la columna *target* (`Churn`) y columnas relevantes por patrones.\n",
        "- Se realiza **one-hot encoding** para variables categóricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab48cca",
      "metadata": {
        "id": "eab48cca"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "CSV_PATH = \"/mnt/data/telecomx_churn_clean.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "print(\"Shape original:\", df.shape)\n",
        "\n",
        "def find_col(patterns, cols):\n",
        "    pat = re.compile(\"|\".join(patterns), re.IGNORECASE)\n",
        "    matches = [c for c in cols if pat.search(c)]\n",
        "    return matches[0] if matches else None\n",
        "\n",
        "target_col = find_col([r\"^churn$\", r\"evas\", r\"cancel\", r\"baja\"], df.columns)\n",
        "if not target_col:\n",
        "    raise ValueError(\"No se encontró columna objetivo (Churn). Ajusta patrones.\")\n",
        "\n",
        "df[target_col] = (df[target_col].astype(str).str.strip().str.lower()\n",
        "                  .map({\"yes\":1,\"y\":1,\"true\":1,\"1\":1,\"si\":1,\"sí\":1,\"no\":0,\"n\":0,\"false\":0,\"0\":0})\n",
        "                  .fillna(0).astype(int))\n",
        "\n",
        "id_like = [c for c in df.columns if re.search(r\"(?:^|_)id$|customerid|clientid|folio|uuid|hash\", c, re.IGNORECASE)]\n",
        "df = df.drop(columns=id_like, errors=\"ignore\")\n",
        "print(\"Columnas eliminadas por ID/no predictivas:\", id_like)\n",
        "\n",
        "numeric_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != target_col]\n",
        "categorical_cols = [c for c in df.columns if c not in numeric_cols + [target_col]]\n",
        "\n",
        "print(\"Numéricas:\", len(numeric_cols), \" | Categóricas:\", len(categorical_cols))\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"Shape tras OHE:\", df_encoded.shape)\n",
        "df_encoded.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28dfead2",
      "metadata": {
        "id": "28dfead2"
      },
      "source": [
        "## 2) Desbalance de clases\n",
        "\n",
        "- Proporción de cancelaciones vs activos.\n",
        "- Si hay desbalance, se intenta **SMOTE** como opción de balanceo (si está disponible).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b655bc6",
      "metadata": {
        "id": "3b655bc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "y = df_encoded[target_col]\n",
        "X = df_encoded.drop(columns=[target_col])\n",
        "\n",
        "ratio = y.mean()\n",
        "print(f\"Tasa de churn (1): {ratio:.4f}  |  Activos (0): {1-ratio:.4f}\")\n",
        "\n",
        "from collections import Counter\n",
        "print(\"Distribución de clases:\", Counter(y))\n",
        "\n",
        "is_imbalanced = (ratio < 0.35) or (ratio > 0.65)\n",
        "print(\"¿Desbalance notable?:\", is_imbalanced)\n",
        "\n",
        "X_bal, y_bal = X.copy(), y.copy()\n",
        "\n",
        "if is_imbalanced:\n",
        "    try:\n",
        "        from imblearn.over_sampling import SMOTE\n",
        "        sm = SMOTE(random_state=42)\n",
        "        X_bal, y_bal = sm.fit_resample(X, y)\n",
        "        print(\"SMOTE aplicado. Nueva distribución:\", Counter(y_bal))\n",
        "    except Exception as e:\n",
        "        print(\"No se pudo aplicar SMOTE. Continuamos sin oversampling. Detalle:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a7c903e",
      "metadata": {
        "id": "5a7c903e"
      },
      "source": [
        "## 3) Visualizaciones (correlaciones y relaciones con churn)\n",
        "\n",
        "- **Matriz de correlación** (numéricas)\n",
        "- **Tiempo de contrato (tenure) × Churn** (boxplot)\n",
        "- **Gasto total (TotalCharges) × Churn** (boxplot y scatter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "721da0ba",
      "metadata": {
        "id": "721da0ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_cols_for_corr = [c for c in X.columns if X[c].dtype != 'uint8']\n",
        "num_subset = df[num_cols_for_corr + [target_col]].select_dtypes(include=[np.number])\n",
        "corr = num_subset.corr()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(corr, interpolation='nearest')\n",
        "plt.title('Matriz de Correlación (numéricas)')\n",
        "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "plt.yticks(range(len(corr.index)), corr.index)\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e09d731",
      "metadata": {
        "id": "9e09d731"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re, matplotlib.pyplot as plt\n",
        "\n",
        "tenure_col = None\n",
        "for c in df.columns:\n",
        "    if re.search(r\"tenure|antig\", c, re.IGNORECASE):\n",
        "        tenure_col = c\n",
        "        break\n",
        "\n",
        "if tenure_col:\n",
        "    plt.figure()\n",
        "    groups = [df[df[target_col]==g][tenure_col].dropna() for g in sorted(df[target_col].unique())]\n",
        "    if all(len(g)>0 for g in groups):\n",
        "        plt.boxplot(groups, labels=[str(int(v)) for v in sorted(df[target_col].unique())])\n",
        "        plt.title(f'Tenure por Churn (0=No,1=Sí) — {tenure_col}')\n",
        "        plt.ylabel(tenure_col)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"No se encontró columna de Tenure.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b834213e",
      "metadata": {
        "id": "b834213e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re, matplotlib.pyplot as plt\n",
        "\n",
        "total_col = None\n",
        "for c in df.columns:\n",
        "    if re.search(r\"total.*charge|cargos?.*total\", c, re.IGNORECASE):\n",
        "        total_col = c\n",
        "        break\n",
        "\n",
        "if total_col:\n",
        "    plt.figure()\n",
        "    groups = [df[df[target_col]==g][total_col].dropna() for g in sorted(df[target_col].unique())]\n",
        "    if all(len(g)>0 for g in groups):\n",
        "        plt.boxplot(groups, labels=[str(int(v)) for v in sorted(df[target_col].unique())])\n",
        "        plt.title(f'{total_col} por Churn (0=No,1=Sí)')\n",
        "        plt.ylabel(total_col)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    sample = df.sample(min(3000, len(df)), random_state=42)\n",
        "    plt.figure()\n",
        "    plt.scatter(sample[total_col], sample[target_col], alpha=0.3)\n",
        "    plt.title(f'Scatter: {total_col} vs Churn (0/1)')\n",
        "    plt.xlabel(total_col)\n",
        "    plt.ylabel('Churn')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No se encontró columna de TotalCharges.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099f2693",
      "metadata": {
        "id": "099f2693"
      },
      "source": [
        "## 4) División Train/Test (80/20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f43bd77",
      "metadata": {
        "id": "7f43bd77"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.2, random_state=42, stratify=y_bal)\n",
        "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ade5e8",
      "metadata": {
        "id": "15ade5e8"
      },
      "source": [
        "## 5) Modelos — Regresión Logística (con normalización) y Random Forest (sin normalización)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07b7827",
      "metadata": {
        "id": "b07b7827"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipe_lr = Pipeline([\n",
        "    ('scaler', StandardScaler(with_mean=False)),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "pipe_lr.fit(X_train, y_train)\n",
        "print(\"Entrenado: Regresión Logística\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946cbb6f",
      "metadata": {
        "id": "946cbb6f"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"Entrenado: Random Forest\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d93fd0",
      "metadata": {
        "id": "e8d93fd0"
      },
      "source": [
        "## 6) Evaluación: Accuracy, Precision, Recall, F1, Matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f790fb",
      "metadata": {
        "id": "90f790fb"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(model, X_tr, y_tr, X_te, y_te, name=\"Modelo\"):\n",
        "    y_pred_tr = model.predict(X_tr)\n",
        "    y_pred_te = model.predict(X_te)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy_train': accuracy_score(y_tr, y_pred_tr),\n",
        "        'precision_train': precision_score(y_tr, y_pred_tr, zero_division=0),\n",
        "        'recall_train': recall_score(y_tr, y_pred_tr, zero_division=0),\n",
        "        'f1_train': f1_score(y_tr, y_pred_tr, zero_division=0),\n",
        "        'accuracy_test': accuracy_score(y_te, y_pred_te),\n",
        "        'precision_test': precision_score(y_te, y_pred_te, zero_division=0),\n",
        "        'recall_test': recall_score(y_te, y_pred_te, zero_division=0),\n",
        "        'f1_test': f1_score(y_te, y_pred_te, zero_division=0),\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} — Métricas:\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(y_te, y_pred_te)\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(f'Matriz de Confusión — {name} (Test)')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(2)\n",
        "    plt.xticks(tick_marks, ['No', 'Sí'])\n",
        "    plt.yticks(tick_marks, ['No', 'Sí'])\n",
        "    plt.ylabel('Real')\n",
        "    plt.xlabel('Predicción')\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nReporte de Clasificación (Test):\")\n",
        "    print(classification_report(y_te, y_pred_te, target_names=['No','Sí'], zero_division=0))\n",
        "    return metrics\n",
        "\n",
        "metrics_lr = evaluate(pipe_lr, X_train, y_train, X_test, y_test, name=\"Regresión Logística\")\n",
        "metrics_rf = evaluate(rf, X_train, y_train, X_test, y_test, name=\"Random Forest\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d086ddb",
      "metadata": {
        "id": "8d086ddb"
      },
      "source": [
        "## 7) Interpretabilidad — Coeficientes (LR) e Importancia (RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ca3ad5",
      "metadata": {
        "id": "21ca3ad5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "coef = pd.Series(pipe_lr.named_steps['clf'].coef_[0], index=X_train.columns)\n",
        "coef.sort_values(ascending=False).head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7ce029",
      "metadata": {
        "id": "9b7ce029"
      },
      "outputs": [],
      "source": [
        "\n",
        "coef.sort_values().head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb00839",
      "metadata": {
        "id": "ffb00839"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "imp = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "imp.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed847ea7",
      "metadata": {
        "id": "ed847ea7"
      },
      "source": [
        "## 8) Informe y Recomendaciones\n",
        "\n",
        "- Comparar resultados de LR vs RF (overfitting/underfitting revisando diferencias train/test).\n",
        "- Variables más influyentes según coeficientes (LR) e importancias (RF).\n",
        "- Sugerencias de retención: contratos a 1–2 años, incentivar pagos automáticos, bundles de valor, alertas tempranas con umbral optimizado según objetivo (recall o precision).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}